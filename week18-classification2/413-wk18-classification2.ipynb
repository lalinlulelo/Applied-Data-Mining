{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCC.413 Applied Data Mining\n",
    "# Week 18\n",
    "# Classification 2 (using custom Document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "* [Introduction](#intro)\n",
    "* [Preamble](#preamble)\n",
    "* [Document object](#doc)\n",
    "    - [Dataset](#data)\n",
    "    - [Document processor](#processor)\n",
    "* [Feature Union](#union)\n",
    "* [Classifying other labels](#other)\n",
    "* [Exercise (not assessed)](#ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "## Introduction\n",
    "\n",
    "In the the first classification exercise scikit-learn was used to classify Twitter users as male or female. Vectorization was done via sklearn's CountVectorizer. At the end of the lab exercise, the preprocessing and tokenisation used by CountVectorizer were customised to give greater control of how the text was processed and features extracted. This actually allows for quite a number of features to be implemented, e.g.:\n",
    "\n",
    "- POS tags, by pos-tagging during tokenisation, and returning the pos-tags instead of words.\n",
    "- Function words, by setting the vocabulary of CountVectorizer to a function word list.\n",
    "- Hashtags, mentions and/or emojis, by only returning these in the token list.\n",
    "- Characters/graphemes, rather than codepoints, by \"tokenising\" with \"\\X\".\n",
    "\n",
    "But we are limited to counting things. Another issue is that the processing will be done multiple times each time the pipeline is ran (e.g. for gridsearch).\n",
    "\n",
    "In this lab you will learn how to process texts in advance, saving the token lists and frequency lists produced, and allowing for other features to be extracted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"preamble\"></a>\n",
    "## Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we do all the imports needed in one go. You may import other packages as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ftfy\n",
    "import nltk\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import Binarizer, StandardScaler\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join, splitext, split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of functions for showing classifier results (from first classification lab):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cv_scores_summary(name, scores):\n",
    "    print(\"{}: mean = {:.2f}%, sd = {:.2f}%, min = {:.2f}, max = {:.2f}\".format(name, scores.mean()*100, scores.std()*100, scores.min()*100, scores.max()*100))\n",
    "    \n",
    "def confusion_matrix_heatmap(cm, index):\n",
    "    cmdf = pd.DataFrame(cm, index = index, columns=index)\n",
    "    dims = (5, 5)\n",
    "    fig, ax = plt.subplots(figsize=dims)\n",
    "    sns.heatmap(cmdf, annot=True, cmap=\"coolwarm\", center=0)\n",
    "    ax.set_ylabel('Actual')    \n",
    "    ax.set_xlabel('Predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"doc\"></a>\n",
    "## Document object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define our document object, along with preprocessing tokenisation methods. These are taken (and slightly extended) from the Feature Extraction lab. The document will represent an instance in our classifier, e.g. it could be a collection of a user's Tweets, a single tweet, a longer article, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_re = re.compile(r\"#\\w+\")\n",
    "mention_re = re.compile(r\"@\\w+\")\n",
    "url_re = re.compile(r\"(?:https?://)?(?:[-\\w]+\\.)+[a-zA-Z]{2,9}[-\\w/#~:;.?+=&%@~]*\")\n",
    "\n",
    "def preprocess(text):\n",
    "    p_text = hashtag_re.sub(\"[hashtag]\",text)\n",
    "    p_text = mention_re.sub(\"[mention]\",p_text)\n",
    "    p_text = url_re.sub(\"[url]\",p_text)\n",
    "    p_text = ftfy.fix_text(p_text)\n",
    "    return p_text\n",
    "\n",
    "tokenise_re = re.compile(r\"(\\[[^\\]]+\\]|[-'\\w]+|[^\\s\\w\\[']+)\") #([]|words|other non-space)\n",
    "def tokenise(text):\n",
    "    return tokenise_re.findall(text)\n",
    "\n",
    "class Document:\n",
    "    def __init__(self, meta={}):\n",
    "        self.meta = meta\n",
    "        self.tokens_fql = Counter() #empty Counter, ready to be added to with Counter.update.\n",
    "        self.ht_fql = Counter()\n",
    "        self.num_tokens = 0\n",
    "        \n",
    "    def extract_features_from_text(self, text):\n",
    "        hts = hashtag_re.findall(text)\n",
    "        self.ht_fql.update([ht.lower() for ht in hts])\n",
    "        p_text = preprocess(text)\n",
    "        tokens = tokenise(p_text)\n",
    "        lower_tokens = [t.lower() for t in tokens]\n",
    "        self.num_tokens += len(lower_tokens)\n",
    "        self.tokens_fql.update(lower_tokens) #updating Counter counts items in list, adding to existing Counter items.\n",
    "        \n",
    "    def extract_features_from_texts(self, texts): #texts should be iterable text lines, e.g. read in from file.\n",
    "        for text in texts:\n",
    "            extract_features_from_text(text)\n",
    "            \n",
    "    def average_token_length(self):\n",
    "        sum_lengths = 0\n",
    "        for key, value in self.tokens_fql.items():\n",
    "            sum_lengths += len(key) * value\n",
    "        return sum_lengths / self.num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data\"></a>\n",
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the Twitter celebs again (this time with extra users from around the world), but from JSON files with further metadata available (the data is slightly different from the first classification lab as it was collected later). The method below reads in the json file, extracts the metadata for the user, creates a new Document representing the user, and adds all of the Tweets (extracting features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_celebs_json(folder):\n",
    "    jsonfiles = [join(folder, f) for f in listdir(folder) if isfile(join(folder, f)) and f.endswith(\".json\")]\n",
    "    for jf in jsonfiles:\n",
    "        with open(jf) as f:\n",
    "            data = json.load(f)\n",
    "            handle = data['handle']\n",
    "            gender = data['gender']\n",
    "            age_range = data['age_range']\n",
    "            english = data['english']\n",
    "        print(\"Processing \" + handle)\n",
    "        doc = Document(meta={'handle': handle, 'gender': gender, 'age_range': age_range, 'english': english}) #include metadata\n",
    "        for tweet in data['tweets']:\n",
    "            doc.extract_features_from_text(tweet['text'])\n",
    "        yield doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the corpus by processing the folder of celebs. This will take a little while, but it should only need doing once (unless you change the Document class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing KellyOsbourne\n",
      "Processing yannicklawry\n",
      "Processing NathanFillion\n",
      "Processing geneliad\n",
      "Processing vkhosla\n",
      "Processing ajaydevgn\n",
      "Processing GulPanag\n",
      "Processing garyvee\n",
      "Processing PadmaLakshmi\n",
      "Processing WilliamShatner\n",
      "Processing JesseLumsden28\n",
      "Processing Richard_H\n",
      "Processing Peter_Max\n",
      "Processing JohnCleese\n",
      "Processing howardlindzon\n",
      "Processing robbiewilliams\n",
      "Processing anandmahindra\n",
      "Processing eddievanhalen\n",
      "Processing PaulMcCartney\n",
      "Processing karanjohar\n",
      "Processing LucasdiGrassi\n",
      "Processing SteveNash\n",
      "Processing virsanghvi\n",
      "Processing iyavillania\n",
      "Processing vikramchandra\n",
      "Processing clinton_kelly\n",
      "Processing LisaHannigan\n",
      "Processing RobbieHunter\n",
      "Processing GabrielSaporta\n",
      "Processing camanpour\n",
      "Processing kenghosh\n",
      "Processing ashabhosle\n",
      "Processing ameesha_patel\n",
      "Processing richardbranson\n",
      "Processing JoeySantiago\n",
      "Processing itspetergabriel\n",
      "Processing AnupamPKher\n",
      "Processing Jonnyboy77\n",
      "Processing Winter\n",
      "Processing bobbyllew\n",
      "Processing charlesarthur\n",
      "Processing Goldsack\n",
      "Processing Sia\n",
      "Processing Beverleyknight\n",
      "Processing pierre\n",
      "Processing nickjfrost\n",
      "Processing TomFletcher\n",
      "Processing Jessicaveronica\n",
      "Processing christianmeier\n",
      "Processing ElizabethHurley\n",
      "Processing PritishNandy\n",
      "Processing alex_harvey\n",
      "Processing JoeHockey\n",
      "Processing TomCavalcante1\n",
      "Processing LisaLavie\n",
      "Processing Al_Horford\n",
      "Processing BrentMCM\n",
      "Processing cesarmillan\n",
      "Processing zoecello\n",
      "Processing jem\n",
      "Processing EmmaWatson\n",
      "Processing SashaVujacic\n",
      "Processing AndreWinner\n",
      "Processing ovi8\n",
      "Processing CelinaJaitly\n",
      "Processing NellyFurtado\n",
      "Processing wyclef\n",
      "Processing Bevilaqua41\n",
      "Processing esmeeworld\n",
      "Processing SimonvanKempen\n",
      "Processing JohnLeguizamo\n",
      "Processing AndersFoghR\n",
      "Processing manny_ski\n",
      "Processing mrjakehumphrey\n",
      "Processing CNezzy\n",
      "Processing mercedesnicoll\n",
      "Processing elliegoulding\n",
      "Processing bipsluvurself\n",
      "Processing dwaynederosario\n",
      "Processing iamsrk\n",
      "Processing RealKidPoker\n",
      "Processing stuholden\n",
      "Processing KalimbaMX\n",
      "Processing bjork\n",
      "Processing drewseeley\n",
      "Processing TheScottyNguyen\n",
      "Processing MattBennett\n",
      "Processing Christieluge\n",
      "Processing tomgreenlive\n",
      "Processing RobbieAmell\n",
      "Processing JonSecada\n",
      "Processing JustinTrudeau\n",
      "Processing GavinRossdale\n",
      "Processing KeithUrban\n",
      "Processing JimCarrey\n",
      "Processing RiskyBusinessMB\n",
      "Processing Kristoff87\n",
      "Processing NelsonPiquet\n",
      "Processing DaveNighbor\n",
      "Processing devonkershaw\n",
      "Processing MrKRudd\n",
      "Processing PaulKagame\n",
      "Processing cocolee117\n",
      "Processing simonpegg\n",
      "Processing AvanJogia\n",
      "Processing TerriClarkMusic\n",
      "Processing CharlizeAfrica\n",
      "Processing louiespence\n",
      "Processing DerrenBrown\n",
      "Processing Schwarzenegger\n",
      "Processing antonycotton\n",
      "Processing Pchiddy\n",
      "Processing ShavoOdadjian\n",
      "Processing CraigyFerg\n",
      "Processing GordonRamsay\n",
      "Processing Gerard_McCarthy\n",
      "Processing katenash\n",
      "Processing afoyle3131\n",
      "Processing Padmasree\n",
      "Processing bradcspence\n",
      "Processing Fearnecotton\n",
      "Processing ThaboSefolosha\n",
      "Processing rogergzz\n",
      "Processing yonibloch\n",
      "Processing PhilLaak\n",
      "Processing akselsvindal\n",
      "Processing NICKIMINAJ\n",
      "Processing cindy_klassen\n",
      "Processing sonamakapoor\n",
      "Processing maaskantmartijn\n",
      "Processing EllisMate\n",
      "Processing Speedskater01\n",
      "Processing DP_57\n",
      "Processing AliVelshi\n",
      "Processing R_Roddy_Piper\n",
      "Processing narendramodi\n",
      "Processing EyeOfJackieChan\n",
      "Processing PaoloNutini\n",
      "Processing commie22\n",
      "Processing ahj\n",
      "Processing NajibRazak\n",
      "Processing GReefah\n",
      "Processing rui\n",
      "Processing bobburnquist\n",
      "Processing andrerieu\n",
      "Processing BDUTT\n",
      "Processing SarahBrownUK\n",
      "Processing chuckcomeau\n",
      "Processing djrap\n",
      "Processing JeffBatch\n",
      "Processing RickSanchezTV\n",
      "Processing deespeak\n",
      "Processing JColeNC\n",
      "Processing ChandraCrawford\n",
      "Processing annemurray1\n",
      "Processing Slash\n",
      "Processing s_vakarchuk\n",
      "Processing jessicalowndes\n",
      "Processing kathryn_kang\n",
      "Processing jamiecullum\n",
      "Processing GreenLife52\n",
      "Processing RealDMitchell\n",
      "Processing timoreilly\n",
      "Processing tabathacoffey\n",
      "Processing jpmontoya\n",
      "Processing cmoffat\n",
      "Processing priyankachopra\n",
      "Processing bifnaked\n",
      "Processing loic\n",
      "Processing aasif\n",
      "Processing Drake\n",
      "Processing howiemandel\n",
      "Processing hyphen18\n",
      "Processing mrjaymanuel\n",
      "Processing Robin_Leach\n",
      "Processing Mike_Rann\n",
      "Processing noushskaugen\n",
      "Processing YaoMing\n",
      "Processing joebrooksmusic\n",
      "Processing cocorocha\n",
      "Processing neilhimself\n",
      "Processing LalitKModi\n",
      "Processing JennHeil\n",
      "Processing michelkreder\n",
      "Processing TheRealSimonCho\n",
      "Processing samantharonson\n",
      "Processing rubarrichello\n",
      "Processing IanJamesPoulter\n",
      "Processing orianthi\n",
      "Processing Xiaxue\n",
      "Processing imogenheap\n",
      "Processing DiegoBoneta\n",
      "Processing GrahamNishikawa\n",
      "Processing ItsStephRice\n",
      "Processing amirkingkhan\n",
      "Processing natashabdnfield\n",
      "Processing 27bslash6\n",
      "Processing stephenfry\n",
      "Processing khoi\n",
      "Processing BeingSalmanKhan\n",
      "Processing JoseCanseco\n",
      "Processing vitorbelfort\n",
      "Processing shahidkapoor\n",
      "Processing robertpopper\n",
      "Processing eddieizzard\n",
      "Processing stephenharper\n",
      "Processing DAVID_A_SLADE\n",
      "Processing shaymitch\n",
      "Processing russellcrowe\n",
      "Processing StellaMcCartney\n",
      "Processing duttypaul\n",
      "Processing cricketaakash\n",
      "Processing FreddyAdu\n",
      "Processing Todd_McFarlane\n",
      "Processing mrjimsturgess\n",
      "Processing JuliaGillard\n",
      "Processing LeonelGOficial\n",
      "Processing jk_rowling\n",
      "Processing OKKenna\n",
      "Processing PahlaviReza\n",
      "Processing jordysmith88\n",
      "Processing IvanBabikov\n",
      "Processing FareedZakaria\n",
      "Processing HIDEO_KOJIMA_EN\n",
      "Processing iamfefemusic\n",
      "Processing strombo\n",
      "Processing shreyaghoshal\n",
      "Processing Mikkelson12\n",
      "Processing janibrajkovic\n",
      "Processing SeppBlatter\n",
      "Processing sanjayjee\n",
      "Processing SenRehmanMalik\n",
      "Processing charltonbrooker\n",
      "Processing akshaykumar\n",
      "Processing Y_Strahovski\n",
      "Processing MarcusCooks\n",
      "Processing TheRealMCMAGIC\n",
      "Processing nathenstridge\n",
      "Processing rustyrockets\n",
      "Processing ramansundar\n",
      "Processing EstelleDarlings\n",
      "Processing MargaretAtwood\n",
      "Processing Marsha_Thomason\n",
      "Processing HasheemTheDream\n",
      "Processing joemcelderry91\n",
      "Processing rosemaryCNN\n",
      "Processing serafinowicz\n",
      "Processing mattdusk\n",
      "Processing sergiompaulinho\n",
      "Processing OzzyOsbourne\n",
      "Processing jaysean\n",
      "Processing RtHon_JohnKey\n",
      "Processing lilyallen\n",
      "Processing TheVijayMallya\n",
      "Processing j3r3bear\n",
      "Processing ShashiTharoor\n",
      "Processing Rickontour\n",
      "Processing CadelOfficial\n",
      "Processing scobie\n",
      "Processing ShaneWarne\n",
      "Processing IAmAnushka\n",
      "Processing AmandaHolden\n",
      "Processing PAULVANDYK\n",
      "Processing duttsanjay\n",
      "Processing Cristiano\n",
      "Processing johnrobertsFox\n",
      "Processing JulianM\n",
      "Processing bishter\n",
      "Processing VictoriaCoren\n",
      "Processing lights\n",
      "Processing JohanBruyneel\n",
      "Processing Sally_Fitz\n",
      "Processing SebLefebvre\n",
      "Processing julianperretta\n",
      "Processing DuncanBannatyne\n",
      "Processing gallinari8888\n",
      "Processing zaza27\n",
      "Processing TimWestwood\n",
      "Processing ariannahuff\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "corpus.extend(import_celebs_json(\"celebs-json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the gender metadata from the Documents as our label/class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [d.meta['gender'] for d in corpus]\n",
    "X = corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also perform the usual train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223 56\n",
      "223 56\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state = 0, stratify=y)\n",
    "print(len(X_train), len(X_test))\n",
    "print(len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"processor\"></a>\n",
    "### Document processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our train/test instances in our custom class to hold the features, we need to build a custom `Transformer` which takes in one dataset and returns a new dataset. Here we need to take in a list of `Document` objects and transform it into a set of features. We build a simple class for this, which overrides the transform method. The intention is for a list of `Document` objects to be passed into the transformer, and a parameter-defined (callable) method is used to extract the featuress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentProcessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, process_method):\n",
    "        self.process_method = process_method\n",
    "    \n",
    "    def fit(self, X, y=None): #no fitting necessary, although could use this to build a vocabulary for all documents, and then limit to set (e.g. top 1000).\n",
    "        return self\n",
    "\n",
    "    def transform(self, documents):\n",
    "        for document in documents:\n",
    "            yield self.process_method(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some example methods for returning the token frequency list, hashtag frequency list, or some text statistics from the `Document`. These can be edited and added to as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens_fql(document):\n",
    "    return document.tokens_fql\n",
    "\n",
    "def get_ht_fql(document):\n",
    "    return document.ht_fql\n",
    "\n",
    "def get_text_stats(document):\n",
    "    ttr = len(document.tokens_fql) / document.num_tokens\n",
    "    return {'avg_token_length': document.average_token_length(), 'ttr': ttr }\n",
    "\n",
    "def read_list(file):\n",
    "    with open(file) as f:\n",
    "        items = []\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            items.append(line.strip())\n",
    "    return items\n",
    "\n",
    "fws = read_list(\"functionwords.txt\")\n",
    "\n",
    "def get_fws_fql(document):\n",
    "    fws_fql = Counter({t: document.tokens_fql[t] for t in fws}) #dict comprehension, t: fql[t] is token: freq.\n",
    "    return +fws_fql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a pipeline with the `DocumentProcessor` as the first step, extract hashtag frequencies as features. The output from the new `DocumentProcessor` is then passed to a [`DictVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html#sklearn.feature_extraction.DictVectorizer), which transforms the features into a vector (scipy.sparse matrix), which can be used with other sklearn steps. To demontrate, we pass to a logistic regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('processor', DocumentProcessor(process_method = get_ht_fql)),\n",
    "    ('vectorizer', DictVectorizer()),\n",
    "    ('standardize', StandardScaler(with_mean=False)),\n",
    "    ('clf', LogisticRegression(solver='liblinear', random_state=0)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: mean = 73.84%, sd = 3.83%, min = 67.86, max = 78.57\n",
      "Precision: mean = 71.34%, sd = 8.75%, min = 58.47, max = 82.48\n",
      "Recall: mean = 73.84%, sd = 3.83%, min = 67.86, max = 78.57\n",
      "F1: mean = 68.37%, sd = 4.35%, min = 61.57, max = 74.38\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_validate(model, X, y, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=0), return_train_score=False, scoring=['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted'])\n",
    "print_cv_scores_summary(\"Accuracy\", cv_scores['test_accuracy'])\n",
    "print_cv_scores_summary(\"Precision\", cv_scores['test_precision_weighted'])\n",
    "print_cv_scores_summary(\"Recall\", cv_scores['test_recall_weighted'])\n",
    "print_cv_scores_summary(\"F1\", cv_scores['test_f1_weighted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"union\"></a>\n",
    "## Feature Union\n",
    "\n",
    "All the pipelines we have used so far have been simple linear sequences of steps. With [`FeatureUnion`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html#sklearn.pipeline.FeatureUnion) we can have complex branched sequences, where different features, or different parts of the text are processed separately. The results are then concatenated together into a composite vector. We could, for example, read in a user's bio separately from the rest of their text, we could even utilise metadata (such as usernames to predict gender), or other data such as profile images.\n",
    "\n",
    "Below we utilise different featuresets available from the Document instances and concatenate them together simply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('text_union', FeatureUnion(\n",
    "        transformer_list = [\n",
    "            ('ht_features', Pipeline([\n",
    "                ('ht_processor', DocumentProcessor(process_method = get_ht_fql)),\n",
    "                ('ht_vectorizer', DictVectorizer()),\n",
    "            ])),\n",
    "            ('fws_features', Pipeline([\n",
    "                ('fws_processor', DocumentProcessor(process_method = get_fws_fql)),\n",
    "                ('fws_vectorizer', DictVectorizer()),\n",
    "            ])),\n",
    "            ('stats_features', Pipeline([\n",
    "                ('stats_processor', DocumentProcessor(process_method = get_text_stats)),\n",
    "                ('stats_vectorizer', DictVectorizer()),\n",
    "            ])),\n",
    "        ],\n",
    "    )),\n",
    "    ('standardize', StandardScaler(with_mean=False)),\n",
    "    ('clf', LogisticRegression(solver='liblinear', random_state=0)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: mean = 72.76%, sd = 3.07%, min = 69.64, max = 78.57\n",
      "Precision: mean = 63.14%, sd = 11.72%, min = 51.02, max = 83.42\n",
      "Recall: mean = 72.76%, sd = 3.07%, min = 69.64, max = 78.57\n",
      "F1: mean = 64.49%, sd = 4.76%, min = 59.52, max = 72.80\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_validate(model, X, y, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=0), return_train_score=False, scoring=['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted'])\n",
    "print_cv_scores_summary(\"Accuracy\", cv_scores['test_accuracy'])\n",
    "print_cv_scores_summary(\"Precision\", cv_scores['test_precision_weighted'])\n",
    "print_cv_scores_summary(\"Recall\", cv_scores['test_recall_weighted'])\n",
    "print_cv_scores_summary(\"F1\", cv_scores['test_f1_weighted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"other\"></a>\n",
    "## Classifying other labels\n",
    "\n",
    "We have been working on binary classification of gender. Other user metadata can be predicted also, with the age_range and English variety being present (if you use the larger datasets provided).\n",
    "\n",
    "Looking at age, there are 5 age ranges present, plus some marked as \"unknown\". We need to remove the \"unknowns\" as predicting as 'unknown' does not make sense. You could predict these unknowns with your trained classifier at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'25-34', '35-44', '45-54', '55-64', '65+', 'unknown'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([d.meta['age_range'] for d in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_X = [d for d in X if d.meta['age_range'] != 'unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(age_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 instances have been removed. We need to extract the new labels also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_y = [d.meta['age_range'] for d in age_X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do a train-test split as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_X_train, age_X_test, age_y_train, age_y_test = train_test_split(age_X, age_y, test_size=0.2, random_state = 0, stratify=age_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a pipeline with feature union similar to earlier, except we are now also using grid search, including if to include function words or all words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=0, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('union',\n",
       "                                        FeatureUnion(n_jobs=None,\n",
       "                                                     transformer_list=[('ht',\n",
       "                                                                        Pipeline(memory=None,\n",
       "                                                                                 steps=[('processor',\n",
       "                                                                                         DocumentProcessor(process_method=<function get_ht_fql at 0x7f44dd1a2730>)),\n",
       "                                                                                        ('vectorizer',\n",
       "                                                                                         DictVectorizer(dtype=<class 'numpy.float...\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'selector__k': [50, 100, 150, 500],\n",
       "                         'union__word__processor__process_method': [<function get_fws_fql at 0x7f44e0276510>,\n",
       "                                                                    <function get_tokens_fql at 0x7f44dd1a28c8>]},\n",
       "             pre_dispatch='2*n_jobs', refit='f1_weighted',\n",
       "             return_train_score=False,\n",
       "             scoring=['accuracy', 'precision_weighted', 'recall_weighted',\n",
       "                      'f1_weighted'],\n",
       "             verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list = [\n",
    "            ('ht', Pipeline([\n",
    "                ('processor', DocumentProcessor(process_method = get_ht_fql)),\n",
    "                ('vectorizer', DictVectorizer()),\n",
    "            ])),\n",
    "            ('word', Pipeline([\n",
    "                ('processor', DocumentProcessor(process_method = None)), # to be set by grid search.\n",
    "                ('vectorizer', DictVectorizer()),\n",
    "            ])),\n",
    "            ('stats', Pipeline([\n",
    "                ('processor', DocumentProcessor(process_method = get_text_stats)),\n",
    "                ('vectorizer', DictVectorizer()),\n",
    "            ])),\n",
    "        ],\n",
    "    )),\n",
    "    ('selector', SelectKBest(score_func = chi2)),\n",
    "    ('standardize', StandardScaler(with_mean=False)),\n",
    "    ('clf', LogisticRegression(solver='liblinear', random_state=0, multi_class='ovr')),\n",
    "])\n",
    "\n",
    "param_grid={\n",
    "    'union__word__processor__process_method': [get_fws_fql, get_tokens_fql],\n",
    "    'selector__k': [50, 100, 150, 500],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "search = GridSearchCV(model, cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0), \n",
    "                      return_train_score = False, \n",
    "                      scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted'],\n",
    "                      refit = 'f1_weighted',\n",
    "                      param_grid = param_grid\n",
    "                     )\n",
    "\n",
    "search.fit(age_X_train, age_y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_selector__k</th>\n",
       "      <th>param_union__word__processor__process_method</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_recall_weighted</th>\n",
       "      <th>rank_test_recall_weighted</th>\n",
       "      <th>split0_test_f1_weighted</th>\n",
       "      <th>split1_test_f1_weighted</th>\n",
       "      <th>split2_test_f1_weighted</th>\n",
       "      <th>split3_test_f1_weighted</th>\n",
       "      <th>split4_test_f1_weighted</th>\n",
       "      <th>mean_test_f1_weighted</th>\n",
       "      <th>std_test_f1_weighted</th>\n",
       "      <th>rank_test_f1_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.260366</td>\n",
       "      <td>0.009038</td>\n",
       "      <td>0.048773</td>\n",
       "      <td>0.005765</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;function get_fws_fql at 0x7f44e0276510&gt;</td>\n",
       "      <td>{'selector__k': 50, 'union__word__processor__p...</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050196</td>\n",
       "      <td>6</td>\n",
       "      <td>0.329484</td>\n",
       "      <td>0.259975</td>\n",
       "      <td>0.309595</td>\n",
       "      <td>0.292125</td>\n",
       "      <td>0.367914</td>\n",
       "      <td>0.311819</td>\n",
       "      <td>0.036164</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.981786</td>\n",
       "      <td>0.069719</td>\n",
       "      <td>0.160825</td>\n",
       "      <td>0.007066</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;function get_tokens_fql at 0x7f44dd1a28c8&gt;</td>\n",
       "      <td>{'selector__k': 50, 'union__word__processor__p...</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058898</td>\n",
       "      <td>3</td>\n",
       "      <td>0.370598</td>\n",
       "      <td>0.348071</td>\n",
       "      <td>0.386829</td>\n",
       "      <td>0.228760</td>\n",
       "      <td>0.299484</td>\n",
       "      <td>0.326748</td>\n",
       "      <td>0.057153</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.202288</td>\n",
       "      <td>0.004574</td>\n",
       "      <td>0.039509</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;function get_fws_fql at 0x7f44e0276510&gt;</td>\n",
       "      <td>{'selector__k': 100, 'union__word__processor__...</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055599</td>\n",
       "      <td>5</td>\n",
       "      <td>0.402974</td>\n",
       "      <td>0.276394</td>\n",
       "      <td>0.273256</td>\n",
       "      <td>0.311209</td>\n",
       "      <td>0.418487</td>\n",
       "      <td>0.336464</td>\n",
       "      <td>0.062278</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.904414</td>\n",
       "      <td>0.008614</td>\n",
       "      <td>0.157312</td>\n",
       "      <td>0.003605</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;function get_tokens_fql at 0x7f44dd1a28c8&gt;</td>\n",
       "      <td>{'selector__k': 100, 'union__word__processor__...</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041710</td>\n",
       "      <td>7</td>\n",
       "      <td>0.296779</td>\n",
       "      <td>0.311830</td>\n",
       "      <td>0.279291</td>\n",
       "      <td>0.252268</td>\n",
       "      <td>0.397089</td>\n",
       "      <td>0.307451</td>\n",
       "      <td>0.049003</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.227940</td>\n",
       "      <td>0.033555</td>\n",
       "      <td>0.043091</td>\n",
       "      <td>0.008735</td>\n",
       "      <td>150</td>\n",
       "      <td>&lt;function get_fws_fql at 0x7f44e0276510&gt;</td>\n",
       "      <td>{'selector__k': 150, 'union__word__processor__...</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.395349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073876</td>\n",
       "      <td>3</td>\n",
       "      <td>0.465097</td>\n",
       "      <td>0.341639</td>\n",
       "      <td>0.316907</td>\n",
       "      <td>0.322877</td>\n",
       "      <td>0.230441</td>\n",
       "      <td>0.335392</td>\n",
       "      <td>0.075333</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.095868</td>\n",
       "      <td>0.075297</td>\n",
       "      <td>0.178113</td>\n",
       "      <td>0.016795</td>\n",
       "      <td>150</td>\n",
       "      <td>&lt;function get_tokens_fql at 0x7f44dd1a28c8&gt;</td>\n",
       "      <td>{'selector__k': 150, 'union__word__processor__...</td>\n",
       "      <td>0.395349</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051676</td>\n",
       "      <td>2</td>\n",
       "      <td>0.368398</td>\n",
       "      <td>0.333389</td>\n",
       "      <td>0.257442</td>\n",
       "      <td>0.301838</td>\n",
       "      <td>0.420097</td>\n",
       "      <td>0.336233</td>\n",
       "      <td>0.055618</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.218314</td>\n",
       "      <td>0.022738</td>\n",
       "      <td>0.040037</td>\n",
       "      <td>0.002340</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;function get_fws_fql at 0x7f44e0276510&gt;</td>\n",
       "      <td>{'selector__k': 500, 'union__word__processor__...</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041849</td>\n",
       "      <td>8</td>\n",
       "      <td>0.377409</td>\n",
       "      <td>0.290378</td>\n",
       "      <td>0.275787</td>\n",
       "      <td>0.285983</td>\n",
       "      <td>0.315949</td>\n",
       "      <td>0.309101</td>\n",
       "      <td>0.036627</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.043549</td>\n",
       "      <td>0.099341</td>\n",
       "      <td>0.178018</td>\n",
       "      <td>0.033796</td>\n",
       "      <td>500</td>\n",
       "      <td>&lt;function get_tokens_fql at 0x7f44dd1a28c8&gt;</td>\n",
       "      <td>{'selector__k': 500, 'union__word__processor__...</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059583</td>\n",
       "      <td>1</td>\n",
       "      <td>0.451864</td>\n",
       "      <td>0.279265</td>\n",
       "      <td>0.329457</td>\n",
       "      <td>0.296150</td>\n",
       "      <td>0.359812</td>\n",
       "      <td>0.343310</td>\n",
       "      <td>0.060949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.260366      0.009038         0.048773        0.005765   \n",
       "1       0.981786      0.069719         0.160825        0.007066   \n",
       "2       0.202288      0.004574         0.039509        0.001394   \n",
       "3       0.904414      0.008614         0.157312        0.003605   \n",
       "4       0.227940      0.033555         0.043091        0.008735   \n",
       "5       1.095868      0.075297         0.178113        0.016795   \n",
       "6       0.218314      0.022738         0.040037        0.002340   \n",
       "7       1.043549      0.099341         0.178018        0.033796   \n",
       "\n",
       "  param_selector__k param_union__word__processor__process_method  \\\n",
       "0                50     <function get_fws_fql at 0x7f44e0276510>   \n",
       "1                50  <function get_tokens_fql at 0x7f44dd1a28c8>   \n",
       "2               100     <function get_fws_fql at 0x7f44e0276510>   \n",
       "3               100  <function get_tokens_fql at 0x7f44dd1a28c8>   \n",
       "4               150     <function get_fws_fql at 0x7f44e0276510>   \n",
       "5               150  <function get_tokens_fql at 0x7f44dd1a28c8>   \n",
       "6               500     <function get_fws_fql at 0x7f44e0276510>   \n",
       "7               500  <function get_tokens_fql at 0x7f44dd1a28c8>   \n",
       "\n",
       "                                              params  split0_test_accuracy  \\\n",
       "0  {'selector__k': 50, 'union__word__processor__p...              0.348837   \n",
       "1  {'selector__k': 50, 'union__word__processor__p...              0.418605   \n",
       "2  {'selector__k': 100, 'union__word__processor__...              0.418605   \n",
       "3  {'selector__k': 100, 'union__word__processor__...              0.348837   \n",
       "4  {'selector__k': 150, 'union__word__processor__...              0.465116   \n",
       "5  {'selector__k': 150, 'union__word__processor__...              0.395349   \n",
       "6  {'selector__k': 500, 'union__word__processor__...              0.418605   \n",
       "7  {'selector__k': 500, 'union__word__processor__...              0.488372   \n",
       "\n",
       "   split1_test_accuracy  split2_test_accuracy  ...  std_test_recall_weighted  \\\n",
       "0              0.279070              0.348837  ...                  0.050196   \n",
       "1              0.372093              0.418605  ...                  0.058898   \n",
       "2              0.302326              0.302326  ...                  0.055599   \n",
       "3              0.348837              0.302326  ...                  0.041710   \n",
       "4              0.348837              0.395349  ...                  0.073876   \n",
       "5              0.372093              0.302326  ...                  0.051676   \n",
       "6              0.325581              0.302326  ...                  0.041849   \n",
       "7              0.325581              0.348837  ...                  0.059583   \n",
       "\n",
       "   rank_test_recall_weighted  split0_test_f1_weighted  \\\n",
       "0                          6                 0.329484   \n",
       "1                          3                 0.370598   \n",
       "2                          5                 0.402974   \n",
       "3                          7                 0.296779   \n",
       "4                          3                 0.465097   \n",
       "5                          2                 0.368398   \n",
       "6                          8                 0.377409   \n",
       "7                          1                 0.451864   \n",
       "\n",
       "   split1_test_f1_weighted  split2_test_f1_weighted  split3_test_f1_weighted  \\\n",
       "0                 0.259975                 0.309595                 0.292125   \n",
       "1                 0.348071                 0.386829                 0.228760   \n",
       "2                 0.276394                 0.273256                 0.311209   \n",
       "3                 0.311830                 0.279291                 0.252268   \n",
       "4                 0.341639                 0.316907                 0.322877   \n",
       "5                 0.333389                 0.257442                 0.301838   \n",
       "6                 0.290378                 0.275787                 0.285983   \n",
       "7                 0.279265                 0.329457                 0.296150   \n",
       "\n",
       "   split4_test_f1_weighted  mean_test_f1_weighted  std_test_f1_weighted  \\\n",
       "0                 0.367914               0.311819              0.036164   \n",
       "1                 0.299484               0.326748              0.057153   \n",
       "2                 0.418487               0.336464              0.062278   \n",
       "3                 0.397089               0.307451              0.049003   \n",
       "4                 0.230441               0.335392              0.075333   \n",
       "5                 0.420097               0.336233              0.055618   \n",
       "6                 0.315949               0.309101              0.036627   \n",
       "7                 0.359812               0.343310              0.060949   \n",
       "\n",
       "   rank_test_f1_weighted  \n",
       "0                      6  \n",
       "1                      5  \n",
       "2                      2  \n",
       "3                      8  \n",
       "4                      4  \n",
       "5                      3  \n",
       "6                      7  \n",
       "7                      1  \n",
       "\n",
       "[8 rows x 39 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'selector__k': 500,\n",
       " 'union__word__processor__process_method': <function __main__.get_tokens_fql(document)>}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.37037037037037035\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       25-34       0.56      0.62      0.59        16\n",
      "       35-44       0.33      0.50      0.40        14\n",
      "       45-54       0.22      0.15      0.18        13\n",
      "       55-64       0.17      0.14      0.15         7\n",
      "         65+       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.37        54\n",
      "   macro avg       0.26      0.28      0.26        54\n",
      "weighted avg       0.33      0.37      0.34        54\n",
      "\n",
      "[[10  4  1  1  0]\n",
      " [ 4  7  1  2  0]\n",
      " [ 4  6  2  1  0]\n",
      " [ 0  1  5  1  0]\n",
      " [ 0  3  0  1  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = search.predict(age_X_test)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(age_y_test, predictions))\n",
    "print(classification_report(age_y_test, predictions))\n",
    "print(confusion_matrix(age_y_test, predictions))\n",
    "\n",
    "confusion_matrix_heatmap(confusion_matrix(age_y_test,predictions), search.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ex\"></a>\n",
    "## Exercise (not assessed)\n",
    "\n",
    "Try adding and improving the features used for age classification, and evaluate your results with different setups.\n",
    "\n",
    "\n",
    "### Advanced tasks:\n",
    "\n",
    "- You could try predicting the precise age with a regression model (the age is in the json metadata). See: https://dl.acm.org/citation.cfm?id=2107651.\n",
    "- Or you could try predicting age and gender together, either mutli-class pairs, or through a classification tree, e.g. predict gender first, then narrowing age ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
